{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995fbf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Status: 200\n",
      "Final URL: https://example.com/\n",
      "Content-Type: text/html\n",
      "Content-Length header: 363\n",
      "Actual body length (bytes): 513\n",
      "---------------------------------------------------\n",
      "HTML Preview (first 500 characters):\n",
      "<!doctype html><html lang=\"en\"><head><title>Example Domain</title><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"><style>body{background:#eee;width:60vw;margin:15vh auto;font-family:system-ui,sans-serif}h1{font-size:1.5em}div{opacity:0.8}a:link,a:visited{color:#348}</style><body><div><h1>Example Domain</h1><p>This domain is for use in documentation examples without needing permission. Avoid use in operations.<p><a href=\"https://iana.org/domains/example\">Learn more</a></div></body></html>\n",
      "\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ======================= TC -1 URL feature Extraction ======================= #\n",
    "import os\n",
    "import sys\n",
    "\n",
    " \n",
    "try:\n",
    "    CURRENT_DIR = os.path.dirname(__file__)\n",
    "except NameError:\n",
    "   \n",
    "    CURRENT_DIR = os.getcwd()\n",
    "\n",
    "PARENT_DIR = os.path.abspath(os.path.join(CURRENT_DIR, \"..\"))\n",
    "if PARENT_DIR not in sys.path:\n",
    "    sys.path.insert(0, PARENT_DIR)\n",
    "\n",
    "from DD_FEATURE_EXTRACTOR_09_21_2025 import safe_requests_get\n",
    "\n",
    "def inspect_url(url: str):\n",
    "    \"\"\"Fetch a URL using safe_requests_get and print key response details.\"\"\"\n",
    "    if safe_requests_get is None:\n",
    "        print(\"safe_requests_get not available; aborting.\")\n",
    "        return\n",
    "    r = safe_requests_get(url)\n",
    "    if r is None:\n",
    "        print(\"Request failed or returned no response object.\")\n",
    "        return\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"Status:\", r.status_code)\n",
    "    print(\"Final URL:\", r.url)\n",
    "    print(\"Content-Type:\", r.headers.get(\"Content-Type\"))\n",
    "    print(\"Content-Length header:\", r.headers.get(\"Content-Length\"))\n",
    "    body_bytes = r.content or b\"\"\n",
    "    print(\"Actual body length (bytes):\", len(body_bytes))\n",
    "    try:\n",
    "        preview = body_bytes[:2000].decode(r.encoding or \"utf-8\", errors=\"replace\")\n",
    "    except Exception:\n",
    "        preview = \"(failed to decode preview)\"\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"HTML Preview (first 500 characters):\")\n",
    "    print(preview)\n",
    "    print(\"---------------------------------------------------\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_url = \"https://example.com\"\n",
    "    inspect_url(test_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f5943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Status: 200\n",
      "Final URL: https://example.com/\n",
      "Content-Type: text/html\n",
      "Content-Length header: 363\n",
      "Actual body length (bytes): 513\n",
      "MD5 Hash of page content: bc2473a18e003bdb249eba5ce893033f\n",
      "---------------------------------------------------\n",
      "HTML Preview (first 500 characters):\n",
      "<!doctype html><html lang=\"en\"><head><title>Example Domain</title><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"><style>body{background:#eee;width:60vw;margin:15vh auto;font-family:system-ui,sans-serif}h1{font-size:1.5em}div{opacity:0.8}a:link,a:visited{color:#348}</style><body><div><h1>Example Domain</h1><p>This domain is for use in documentation examples without needing permission. Avoid use in operations.<p><a href=\"https://iana.org/domains/example\">Learn more</a></div></\n",
      "---------------------------------------------------\n",
      "\n",
      "✅ MD5 hash: bc2473a18e003bdb249eba5ce893033f\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import hashlib\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Handle path for importing DD_FEATURE_EXTRACTOR_09_21_2025.py\n",
    "# (works inside Jupyter since __file__ is not defined)\n",
    "# ----------------------------------------------------------------------\n",
    "CURRENT_DIR = os.getcwd()                                               # Fallback to current working directory\n",
    "PARENT_DIR = os.path.abspath(os.path.join(CURRENT_DIR, \"..\"))           # Parent directory path\n",
    "if PARENT_DIR not in sys.path:\n",
    "    sys.path.insert(0, PARENT_DIR)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Import safe_requests_get from your extractor module\n",
    "# ----------------------------------------------------------------------\n",
    "try:\n",
    "    from DD_FEATURE_EXTRACTOR_09_21_2025 import safe_requests_get\n",
    "except Exception as exc:\n",
    "    print(\"Failed to import safe_requests_get from DD_FEATURE_EXTRACTOR_09_21_2025:\", exc)\n",
    "    safe_requests_get = None\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Inspect function with MD5 computation\n",
    "# ----------------------------------------------------------------------\n",
    "def inspect_url(url: str):\n",
    "    \"\"\"Fetch a URL using safe_requests_get and print response info + MD5 hash.\"\"\"\n",
    "    if safe_requests_get is None:\n",
    "        print(\"safe_requests_get not available; aborting.\")\n",
    "        return None\n",
    "\n",
    "    r = safe_requests_get(url)\n",
    "    if r is None:\n",
    "        print(\"Request failed or returned no response object.\")\n",
    "        return None\n",
    "\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"Status:\", r.status_code)\n",
    "    print(\"Final URL:\", r.url)\n",
    "    print(\"Content-Type:\", r.headers.get(\"Content-Type\"))\n",
    "    print(\"Content-Length header:\", r.headers.get(\"Content-Length\"))\n",
    "\n",
    "    body_bytes = r.content or b\"\"\n",
    "    print(\"Actual body length (bytes):\", len(body_bytes))\n",
    "\n",
    "    # ---- Compute MD5 hash of HTML content ----\n",
    "    md5_hash = hashlib.md5(body_bytes).hexdigest()\n",
    "    print(\"MD5 Hash of page content:\", md5_hash)\n",
    "\n",
    "    try:\n",
    "        preview = body_bytes[:500].decode(r.encoding or \"utf-8\", errors=\"replace\")\n",
    "    except Exception:\n",
    "        preview = \"(failed to decode preview)\"\n",
    "\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"HTML Preview (first 500 characters):\")\n",
    "    print(preview)\n",
    "    print(\"---------------------------------------------------\")\n",
    "\n",
    "    return md5_hash\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Example test\n",
    "# ----------------------------------------------------------------------\n",
    "test_url = \"https://example.com\"\n",
    "md5_value = inspect_url(test_url)\n",
    "print(f\"\\n✅ MD5 hash: {md5_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c214ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def normalize_domain(url_or_domain: str) -> str:\n",
    "    \"\"\"Extract and normalize the domain from a URL or domain string.\"\"\"\n",
    "    if not url_or_domain:\n",
    "        return \"\"\n",
    "\n",
    "    # Ensure lowercase\n",
    "    text = url_or_domain.strip().lower()\n",
    "\n",
    "    # Add scheme if missing (needed for urlparse)\n",
    "    if not text.startswith((\"http://\", \"https://\")):\n",
    "        text = \"http://\" + text\n",
    "\n",
    "    try:\n",
    "        parsed = urlparse(text)\n",
    "        host = parsed.netloc or parsed.path  # handle 'example.com' case\n",
    "        # Remove leading 'www.' if present\n",
    "        if host.startswith(\"www.\"):\n",
    "            host = host[4:]\n",
    "        # Strip port numbers, e.g., example.com:8080 → example.com\n",
    "        if \":\" in host:\n",
    "            host = host.split(\":\")[0]\n",
    "        return host\n",
    "    except Exception:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee96553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing domain normalization:\n",
      "\n",
      "https://www.google.com/search?q=test          → google.com\n",
      "http://sub.example.co.uk:8080/path/page.html  → sub.example.co.uk\n",
      "example.com                                   → example.com\n",
      "https://EXAMPLE.COM/                          → example.com\n",
      "ftp://my.site.net                             → ftp\n",
      "http://localhost:5000/api                     → localhost\n",
      "                                              → \n"
     ]
    }
   ],
   "source": [
    "test_urls = [\n",
    "    \"https://www.google.com/search?q=test\",\n",
    "    \"http://sub.example.co.uk:8080/path/page.html\",\n",
    "    \"example.com\",\n",
    "    \"https://EXAMPLE.COM/\",\n",
    "    \"ftp://my.site.net\",\n",
    "    \"http://localhost:5000/api\",\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "print(\"Testing domain normalization:\\n\")\n",
    "for u in test_urls:\n",
    "    normalized = normalize_domain(u)\n",
    "    print(f\"{u:45} → {normalized}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecde1d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtractResult(subdomain='login.mail', domain='google', suffix='co.uk', is_private=False)\n",
      "Subdomain: login.mail\n",
      "Domain: google\n",
      "Suffix: co.uk\n"
     ]
    }
   ],
   "source": [
    "import tldextract\n",
    "\n",
    "url = \"https://login.mail.google.co.uk/path/index.html\"\n",
    "result = tldextract.extract(url)\n",
    "\n",
    "print(result)\n",
    "print(\"Subdomain:\", result.subdomain)\n",
    "print(\"Domain:\", result.domain)\n",
    "print(\"Suffix:\", result.suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original Data ===\n",
      "   url_length  num_scripts  has_ip_in_url  suspicious_chars\n",
      "0          50            2              0                 1\n",
      "1         100           10              1                 5\n",
      "2         300           30              0                12\n",
      "3         500           60              1                25\n",
      "\n",
      "=== Scaled Data (after StandardScaler) ===\n",
      "   url_length  num_scripts  has_ip_in_url  suspicious_chars\n",
      "0   -1.052794    -1.050165           -1.0         -1.068995\n",
      "1   -0.772049    -0.692662            1.0         -0.630433\n",
      "2    0.350931     0.201095           -1.0          0.137051\n",
      "3    1.473911     1.541731            1.0          1.562377\n",
      "\n",
      "Mean per feature after scaling (should be ~0):\n",
      "url_length          0.0\n",
      "num_scripts         0.0\n",
      "has_ip_in_url       0.0\n",
      "suspicious_chars    0.0\n",
      "dtype: float64\n",
      "\n",
      "Std per feature after scaling (should be ~1):\n",
      "url_length          1.155\n",
      "num_scripts         1.155\n",
      "has_ip_in_url       1.155\n",
      "suspicious_chars    1.155\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ====================== SCALER TEST ======================= #\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Sample random phishing features (unscaled) --- #\n",
    "data = {\n",
    "    'url_length': [50, 100, 300, 500],\n",
    "    'num_scripts': [2, 10, 30, 60],\n",
    "    'has_ip_in_url': [0, 1, 0, 1],\n",
    "    'suspicious_chars': [1, 5, 12, 25]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"=== Original Data ===\")\n",
    "print(df)\n",
    "\n",
    "# --- Initialize and fit StandardScaler --- #\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Convert scaled array back to DataFrame\n",
    "scaled_df = pd.DataFrame(scaled, columns=df.columns)\n",
    "print(\"\\n=== Scaled Data (after StandardScaler) ===\")\n",
    "print(scaled_df)\n",
    "\n",
    "# --- Check mean and std deviation --- #\n",
    "print(\"\\nMean per feature after scaling (should be ~0):\")\n",
    "print(np.round(scaled_df.mean(), 3))\n",
    "\n",
    "print(\"\\nStd per feature after scaling (should be ~1):\")\n",
    "print(np.round(scaled_df.std(), 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
